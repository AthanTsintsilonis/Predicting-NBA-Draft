{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e732b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import os.path\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d66765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling URLs to scrape\n",
    "years = list(range(2000, 2022))\n",
    "years_custom = list(range(2000, 2022))\n",
    "url_big12 = 'https://www.sports-reference.com/cbb/conferences/big-12/{}-stats.html'\n",
    "url_sec = 'https://www.sports-reference.com/cbb/conferences/sec/{}-stats.html'\n",
    "url_big10 = 'https://www.sports-reference.com/cbb/conferences/big-ten/{}-stats.html'\n",
    "url_bigeast = 'https://www.sports-reference.com/cbb/conferences/big-east/{}-stats.html'\n",
    "url_pac12 = 'https://www.sports-reference.com/cbb/conferences/pac-12/{}-stats.html'\n",
    "url_acc = 'https://www.sports-reference.com/cbb/conferences/acc/{}-stats.html'\n",
    "url_aac = 'https://www.sports-reference.com/cbb/conferences/aac/{}-stats.html'\n",
    "url_mwc = 'https://www.sports-reference.com/cbb/conferences/mwc/{}-stats.html'\n",
    "url_wcc = 'https://www.sports-reference.com/cbb/conferences/wcc/{}-stats.html'\n",
    "url_a10 = 'https://www.sports-reference.com/cbb/conferences/atlantic-10/{}-stats.html'\n",
    "url_mvc = 'https://www.sports-reference.com/cbb/conferences/mvc/{}-stats.html'\n",
    "url_cusa = 'https://www.sports-reference.com/cbb/conferences/cusa/{}-stats.html'\n",
    "url_col = 'https://www.sports-reference.com/cbb/conferences/colonial/{}-stats.html'\n",
    "url_south = 'https://www.sports-reference.com/cbb/conferences/southern/{}-stats.html'\n",
    "url_wac = 'https://www.sports-reference.com/cbb/conferences/wac/{}-stats.html'\n",
    "url_maac = 'https://www.sports-reference.com/cbb/conferences/maac/{}-stats.html'\n",
    "url_bw = 'https://www.sports-reference.com/cbb/conferences/big-west/{}-stats.html'\n",
    "url_sb = 'https://www.sports-reference.com/cbb/conferences/sun-belt/{}-stats.html'\n",
    "url_ivy = 'https://www.sports-reference.com/cbb/conferences/ivy/{}-stats.html'\n",
    "url_mac = 'https://www.sports-reference.com/cbb/conferences/mac/{}-stats.html'\n",
    "url_as = 'https://www.sports-reference.com/cbb/conferences/atlantic-sun/{}-stats.html'\n",
    "url_ovc = 'https://www.sports-reference.com/cbb/conferences/ovc/{}-stats.html'\n",
    "url_summit = 'https://www.sports-reference.com/cbb/conferences/summit/{}-stats.html'\n",
    "url_big_south = 'https://www.sports-reference.com/cbb/conferences/big-south/{}-stats.html'\n",
    "url_big_sky = 'https://www.sports-reference.com/cbb/conferences/big-sky/{}-stats.html'\n",
    "url_america_east = 'https://www.sports-reference.com/cbb/conferences/america-east/{}-stats.html'\n",
    "url_horizon = 'https://www.sports-reference.com/cbb/conferences/horizon/{}-stats.html'\n",
    "url_patriot = 'https://www.sports-reference.com/cbb/conferences/patriot/{}-stats.html'\n",
    "url_southland = 'https://www.sports-reference.com/cbb/conferences/southland/{}-stats.html'\n",
    "url_northeast = 'https://www.sports-reference.com/cbb/conferences/northeast/{}-stats.html'\n",
    "url_meac = 'https://www.sports-reference.com/cbb/conferences/meac/{}-stats.html'\n",
    "url_swac = 'https://www.sports-reference.com/cbb/conferences/swac/{}-stats.html'\n",
    "url_draft =     'https://www.nbadraft.net/{}-nba-draft-combine-measurements/'\n",
    "url_draft_summary = 'https://basketball.realgm.com/nba/draft/past_drafts/{}'\n",
    "\n",
    "list_of_urls = [\n",
    "url_big12, \n",
    "url_sec, \n",
    "url_big10,\n",
    "url_bigeast,\n",
    "url_pac12,\n",
    "url_acc,\n",
    "url_aac,\n",
    "url_mwc,\n",
    "url_wcc,\n",
    "url_a10,\n",
    "url_mvc,\n",
    "url_cusa,\n",
    "url_col,\n",
    "url_south,\n",
    "url_wac,\n",
    "url_maac,\n",
    "url_bw,\n",
    "url_sb,\n",
    "url_ivy,\n",
    "url_mac,\n",
    "url_as,\n",
    "url_ovc ,\n",
    "url_summit,\n",
    "url_big_south,\n",
    "url_big_sky,\n",
    "url_america_east,\n",
    "url_horizon,\n",
    "url_patriot,\n",
    "url_southland,\n",
    "url_northeast,\n",
    "url_meac,\n",
    "url_swac\n",
    "]\n",
    "#Table ID\n",
    "NCAA_id = 'conference-stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19644134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates File name\n",
    "def generate_name(url, year):\n",
    "    end_index = url[49:].find('/')\n",
    "    name = url[49:49+end_index]+'_'+str(year)\n",
    "    return(name)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f36f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates File Directory\n",
    "def generate_directory(directory, file_name):\n",
    "    generated_directory = directory + '/{}.html'.format(file_name)\n",
    "    return(generated_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a168aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to directory\n",
    "def get_html_request(directory, url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open(generate_directory(directory, generate_name(url, year)), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ee924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /NCAA\n",
    "def get_html_request_NCAA(url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open('NCAA/{}.html'.format(generate_name(url, year)), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910f370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /Draft\n",
    "def get_html_request_draft(url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open('Draft/{}.html'.format(year), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe4780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /NCAA, uses Selenium to execute javascript if required\n",
    "def get_html_api(url):\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    for year in years_custom:        \n",
    "        temp_url = url.format(year)\n",
    "        driver.get(temp_url)\n",
    "        driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "        time.sleep(4)\n",
    "        with open(\"NCAA/{}.html\".format(generate_name(url, year)), \"w+\",encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e65da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searches webpage for all tables\n",
    "def search_url_for_tables(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    return(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8877f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses requests to get html and searches for all tables, returning them as a df with first row as header\n",
    "def get_df_from_url(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    df = pd.read_html(str(tables))[0]\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data unless the header row\n",
    "    df.columns = new_header\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872efe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses requests to get html and searches for all tables, returning them as a df with no header\n",
    "def get_df_from_url_noheader(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    df = pd.read_html(str(tables))[0]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a31b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens html file and extracts table to df from table id\n",
    "def html_to_df_from_tableid(file_name, table_id):\n",
    "    with open('NCAA/{}.html'.format(file_name), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        soup.find('tr', class_= 'over_header').decompose() #Removes 'over_header' element of table\n",
    "        table = soup.find(id=table_id)\n",
    "        df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "#Uses URL to get df based on table id\n",
    "def html_to_df_from_tableid_no_download(url, table_id):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    table = soup.find(id=table_id)\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "#Uses URL to get df based on table class\n",
    "def html_to_df_from_table_class_no_download(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    table = soup.find('table', {'class' : [\"tablesaw\", \"tablesaw-swipe\", \"tablesaw-sortable\"]})\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52bfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes Positons from player names as to only include player name in 'Player' Collumn\n",
    "def clean_player_name(series):\n",
    "    new_series = []\n",
    "    for item in series:\n",
    "        index = 0\n",
    "        for char in reversed(item):\n",
    "            if char.capitalize() == char or char == '-':\n",
    "                index = index - 1\n",
    "            else:\n",
    "                break\n",
    "        new_series.append(item[:index].strip())\n",
    "    return(new_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b100d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts from inches to cm so model can interpret data\n",
    "def inch_to_cm(series):\n",
    "    new_series = []\n",
    "    for measurement in series:\n",
    "        measurement = measurement.strip()\n",
    "        feet = float(measurement[0])\n",
    "        inches = float(measurement[2:-1])\n",
    "        height_inches = feet*12 + inches\n",
    "        height_cm = round(height_inches * 2.54, 2)\n",
    "        new_series.append(height_cm)\n",
    "    return(new_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fac48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes instances in dataset where last character is a non-int value \n",
    "def remove_last_char(series):\n",
    "    new_series = []\n",
    "    for item in series:\n",
    "        if isinstance(item, str):\n",
    "            if item[-1] == '‘' or item[-1] == '′' or item[-1] == '%':\n",
    "                new_series.append(item[:-1])\n",
    "            else:\n",
    "                new_series.append(item)\n",
    "        else:\n",
    "            new_series.append(item)\n",
    "    return(new_series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88937574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players\n",
    "from nba_api.stats.endpoints import draftcombinestats\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "combine_dfs = []\n",
    "for year in years:\n",
    "    combine = draftcombinestats.DraftCombineStats(season_all_time = year)\n",
    "    combine_df = combine.get_data_frames()\n",
    "    combine_dfs.append(combine_df[0])\n",
    "    sleep(0.5)\n",
    "combine_data_df = pd.concat(combine_dfs)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c6a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = list(combine_data_df.columns)\n",
    "columns_to_drop =   ['HEIGHT_W_SHOES',\n",
    "                     'HEIGHT_W_SHOES_FT_IN',\n",
    "                     'HEIGHT_WO_SHOES_FT_IN',\n",
    "                     'WINGSPAN_FT_IN',\n",
    "                     'BODY_FAT_PCT',\n",
    "                     'HAND_LENGTH',\n",
    "                     'HAND_WIDTH',\n",
    "                     'MODIFIED_LANE_AGILITY_TIME',\n",
    "                     'SPOT_FIFTEEN_CORNER_LEFT',\n",
    "                     'SPOT_FIFTEEN_BREAK_LEFT',\n",
    "                     'SPOT_FIFTEEN_TOP_KEY',\n",
    "                     'SPOT_FIFTEEN_BREAK_RIGHT',\n",
    "                     'SPOT_FIFTEEN_CORNER_RIGHT',\n",
    "                     'SPOT_COLLEGE_CORNER_LEFT',\n",
    "                     'SPOT_COLLEGE_BREAK_LEFT',\n",
    "                     'SPOT_COLLEGE_TOP_KEY',\n",
    "                     'SPOT_COLLEGE_BREAK_RIGHT',\n",
    "                     'SPOT_COLLEGE_CORNER_RIGHT',\n",
    "                     'SPOT_NBA_CORNER_LEFT',\n",
    "                     'SPOT_NBA_BREAK_LEFT',\n",
    "                     'SPOT_NBA_TOP_KEY',\n",
    "                     'SPOT_NBA_BREAK_RIGHT',\n",
    "                     'SPOT_NBA_CORNER_RIGHT',\n",
    "                     'OFF_DRIB_FIFTEEN_BREAK_LEFT',\n",
    "                     'OFF_DRIB_FIFTEEN_TOP_KEY',\n",
    "                     'OFF_DRIB_FIFTEEN_BREAK_RIGHT',\n",
    "                     'OFF_DRIB_COLLEGE_BREAK_LEFT',\n",
    "                     'OFF_DRIB_COLLEGE_TOP_KEY',\n",
    "                     'OFF_DRIB_COLLEGE_BREAK_RIGHT',\n",
    "                     'ON_MOVE_FIFTEEN',\n",
    "                     'ON_MOVE_COLLEGE',\n",
    "                     'BENCH_PRESS' \n",
    "                     ]                                       #2016 = none\n",
    "\n",
    "combine_df = combine_data_df.drop(columns = columns_to_drop)\n",
    "combine_df = combine_df.dropna()\n",
    "\n",
    "\n",
    "columns_to_rename = {'PLAYER_NAME': 'Player'}\n",
    "combine_df = combine_df.rename(columns = columns_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9de75615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Age</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenyon Martin</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stromile Swift</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Darius Miles</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marcus Fizer</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mike Miller</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Scottie Lewis</td>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Balsa Koprivica</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jericho Sims</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Raiquan Gray</td>\n",
       "      <td>59</td>\n",
       "      <td>22</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Georgios Kalaitzakis</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player  Pick  Age  Year\n",
       "0          Kenyon Martin     1   22  2000\n",
       "1         Stromile Swift     2   20  2000\n",
       "2           Darius Miles     3   18  2000\n",
       "3           Marcus Fizer     4   21  2000\n",
       "4            Mike Miller     5   20  2000\n",
       "..                   ...   ...  ...   ...\n",
       "25         Scottie Lewis    56   21  2021\n",
       "26       Balsa Koprivica    57   21  2021\n",
       "27          Jericho Sims    58   22  2021\n",
       "28          Raiquan Gray    59   22  2021\n",
       "29  Georgios Kalaitzakis    60   22  2021\n",
       "\n",
       "[1309 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a list of dfs of draft data for each year in years_custom\n",
    "dfs_draft = []\n",
    "for year in years_custom:\n",
    "    url = url_draft_summary.format(year)\n",
    "    dfs = pd.read_html(url)\n",
    "    temp_list = [dfs[0], dfs[1]]  #Note that https://basketball.realgm.com/ will occasionally change webpage layout and therefore indexing may need to be adjusted\n",
    "    temp_df = pd.concat(temp_list)\n",
    "    temp_df['Year'] = year\n",
    "    dfs_draft.append(temp_df)\n",
    "\n",
    "\n",
    "\n",
    "#Gets relevant columns from the draft data dataframes\n",
    "dfs_clean = []\n",
    "relevant_columns = ['Player', 'Pick', 'Age', 'Year']\n",
    "for df in dfs_draft:\n",
    "    df = df[relevant_columns]\n",
    "    dfs_clean.append(df)\n",
    "\n",
    "draft_data_df = pd.concat(dfs_clean)\n",
    "#final = pd.merge(draft_main_df, draft_data_df, on=['Player', 'Year'])\n",
    "draft_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81be247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor url in list_of_urls[]:\\n    get_html_api(url)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapes around 200 webpages from basketball reference, Saves files in /NCAA\n",
    "#Can run it if you would like but Selenium may crash every once in a while\n",
    "#If this occurs I would suggest indexing list_of_urls to avoid scraping pages already scraped before the crash and re-running cell\n",
    "'''\n",
    "for url in list_of_urls[]:\n",
    "    get_html_api(url)\n",
    "'''\n",
    "#All files nessecary already in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "406a57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goes through each HTML file in NCAA and extracts table as a df and adds it to the dfs_college list \n",
    "#If no table/player data in HTML, file is deleted\n",
    "#Cell will take around 5 minutes to run\n",
    "dfs_college = []\n",
    "for url in list_of_urls:\n",
    "    for year in years_custom:\n",
    "        file_name = generate_name(url, year)\n",
    "        path = Path('./NCAA/{}.html'.format(file_name))\n",
    "        if os.path.isfile(path):                                       #Checks if file exists\n",
    "            with open('NCAA/{}.html'.format(file_name), encoding=\"utf-8\") as f:\n",
    "                page = f.read()\n",
    "                soup = BeautifulSoup(page, 'html.parser')\n",
    "                try:                                                   #Creates df from player data table and adds it to a list\n",
    "                    soup.find('tr', class_= 'over_header').decompose() #This will raise AttributeError if there is no player data on webpage\n",
    "                    table = soup.find(id=NCAA_id)                      \n",
    "                    df = pd.read_html(str(table))[0]\n",
    "                    df['Year'] = year\n",
    "                    dfs_college.append(df)\n",
    "                except AttributeError:                                 #If no player data table exists the HTML file is deleted\n",
    "                    f.close()                                          #This occurs because some conferences did not exist until later \n",
    "                    os.remove(path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc0a82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds all college players to a single df and gets relevant collumns\n",
    "college_total = pd.concat(dfs_college)\n",
    "relevant_columns = ['Player', 'Pos', 'G','MP','FG%','2P%','3P%','FT%','PTS.1','TRB.1','AST.1','STL.1','BLK.1','PER','WS','BPM', 'Year']\n",
    "columns_to_rename = {'PTS.1': 'PTS',\n",
    "                    'AST.1': 'AST',\n",
    "                    'STL.1': 'STL',\n",
    "                    'BLK.1': 'BLK',\n",
    "                    'TRB.1': 'TRB'}\n",
    "\n",
    "college_total_clean = college_total.loc[:,relevant_columns]\n",
    "college_total_clean.rename(columns = columns_to_rename , inplace = True)\n",
    "\n",
    "#Merges df containing college player stats and NBA draft info to a single df which is written to total.csv for analysis\n",
    "total = pd.merge(college_total_clean, draft_data_df, on=['Player', 'Year'])\n",
    "total['3P%'] = total['3P%'].fillna(0)\n",
    "total = total.dropna()\n",
    "\n",
    "total.to_csv('total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beda5752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Class</th>\n",
       "      <th>Pos</th>\n",
       "      <th>School</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>PTS.1</th>\n",
       "      <th>TRB.1</th>\n",
       "      <th>AST.1</th>\n",
       "      <th>STL.1</th>\n",
       "      <th>BLK.1</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>35</td>\n",
       "      <td>831</td>\n",
       "      <td>214</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>.524</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>SO</td>\n",
       "      <td>F</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>31</td>\n",
       "      <td>636</td>\n",
       "      <td>163</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>.519</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>39</td>\n",
       "      <td>1124</td>\n",
       "      <td>342</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>.701</td>\n",
       "      <td>10.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>26.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>SO</td>\n",
       "      <td>F</td>\n",
       "      <td>Loyola Marymount</td>\n",
       "      <td>32</td>\n",
       "      <td>282</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>.824</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>JR</td>\n",
       "      <td>F</td>\n",
       "      <td>Loyola Marymount</td>\n",
       "      <td>31</td>\n",
       "      <td>687</td>\n",
       "      <td>138</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>.667</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>SR</td>\n",
       "      <td>F</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>18</td>\n",
       "      <td>461</td>\n",
       "      <td>124</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>.571</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Jordan Bell</td>\n",
       "      <td>FR</td>\n",
       "      <td>F</td>\n",
       "      <td>Northwestern State</td>\n",
       "      <td>26</td>\n",
       "      <td>302</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>.650</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rk       Player Class Pos              School   G    MP  TRB AST STL  ...  \\\n",
       "15  16  Jordan Bell    FR   F              Oregon  35   831  214  47  28  ...   \n",
       "13  14  Jordan Bell    SO   F              Oregon  31   636  163  38  34  ...   \n",
       "15  16  Jordan Bell    JR   F              Oregon  39  1124  342  70  49  ...   \n",
       "10  11  Jordan Bell    SO   F    Loyola Marymount  32   282   57  13  12  ...   \n",
       "11  12  Jordan Bell    JR   F    Loyola Marymount  31   687  138  46  30  ...   \n",
       "16  17  Jordan Bell    SR   F             Pacific  18   461  124  16  21  ...   \n",
       "9   10  Jordan Bell    FR   F  Northwestern State  26   302   84  16   8  ...   \n",
       "\n",
       "     FT% PTS.1 TRB.1 AST.1 STL.1 BLK.1   PER   WS   BPM  Year  \n",
       "15  .524   5.1   6.1   1.3   0.8   2.7  19.2  2.9   7.1  2015  \n",
       "13  .519   6.8   5.3   1.2   1.1   1.7  20.1  2.3   7.0  2016  \n",
       "15  .701  10.9   8.8   1.8   1.3   2.3  26.4  6.2  10.8  2017  \n",
       "10  .824   2.7   1.8   0.4   0.4   0.3  13.2  0.7  -2.6  2019  \n",
       "11  .667   7.2   4.5   1.5   1.0   0.9  16.2  1.6   1.5  2020  \n",
       "16  .571   8.9   6.9   0.9   1.2   0.9  18.8  1.7   4.6  2021  \n",
       "9   .650   4.1   3.2   0.6   0.3   0.4  14.8  0.7  -3.2  2017  \n",
       "\n",
       "[7 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_total.loc[college_total['Player'] == 'Jordan Bell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c37919b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n158 145 Tristan Thompson\\n95  88  David Lee\\n51  48  Jalen Harris\\n118 109 Jalen Johnson\\n75 70   Carl Landry\\n213 196 Dion Waiters\\n15 16   Jordan Bell\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ids \n",
    "'''\n",
    "158 145 Tristan Thompson\n",
    "95  88  David Lee\n",
    "51  48  Jalen Harris\n",
    "118 109 Jalen Johnson\n",
    "75 70   Carl Landry\n",
    "213 196 Dion Waiters\n",
    "15 16   Jordan Bell\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "289b52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.merge(combine_df, total, on='Player')\n",
    "total.to_csv('total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304941ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
