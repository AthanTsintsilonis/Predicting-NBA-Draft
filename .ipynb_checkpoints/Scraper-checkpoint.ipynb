{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e732b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import os.path\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d66765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling URLs to scrape\n",
    "years = list(range(2000, 2023))\n",
    "url_big12 = 'https://www.sports-reference.com/cbb/conferences/big-12/{}-stats.html'\n",
    "url_sec = 'https://www.sports-reference.com/cbb/conferences/sec/{}-stats.html'\n",
    "url_big10 = 'https://www.sports-reference.com/cbb/conferences/big-ten/{}-stats.html'\n",
    "url_bigeast = 'https://www.sports-reference.com/cbb/conferences/big-east/{}-stats.html'\n",
    "url_pac12 = 'https://www.sports-reference.com/cbb/conferences/pac-12/{}-stats.html'\n",
    "url_acc = 'https://www.sports-reference.com/cbb/conferences/acc/{}-stats.html'\n",
    "url_aac = 'https://www.sports-reference.com/cbb/conferences/aac/{}-stats.html'\n",
    "url_mwc = 'https://www.sports-reference.com/cbb/conferences/mwc/{}-stats.html'\n",
    "url_wcc = 'https://www.sports-reference.com/cbb/conferences/wcc/{}-stats.html'\n",
    "url_a10 = 'https://www.sports-reference.com/cbb/conferences/atlantic-10/{}-stats.html'\n",
    "url_mvc = 'https://www.sports-reference.com/cbb/conferences/mvc/{}-stats.html'\n",
    "url_cusa = 'https://www.sports-reference.com/cbb/conferences/cusa/{}-stats.html'\n",
    "url_col = 'https://www.sports-reference.com/cbb/conferences/colonial/{}-stats.html'\n",
    "url_south = 'https://www.sports-reference.com/cbb/conferences/southern/{}-stats.html'\n",
    "url_wac = 'https://www.sports-reference.com/cbb/conferences/wac/{}-stats.html'\n",
    "url_maac = 'https://www.sports-reference.com/cbb/conferences/maac/{}-stats.html'\n",
    "url_bw = 'https://www.sports-reference.com/cbb/conferences/big-west/{}-stats.html'\n",
    "url_sb = 'https://www.sports-reference.com/cbb/conferences/sun-belt/{}-stats.html'\n",
    "url_ivy = 'https://www.sports-reference.com/cbb/conferences/ivy/{}-stats.html'\n",
    "url_mac = 'https://www.sports-reference.com/cbb/conferences/mac/{}-stats.html'\n",
    "url_as = 'https://www.sports-reference.com/cbb/conferences/atlantic-sun/{}-stats.html'\n",
    "url_ovc = 'https://www.sports-reference.com/cbb/conferences/ovc/{}-stats.html'\n",
    "url_summit = 'https://www.sports-reference.com/cbb/conferences/summit/{}-stats.html'\n",
    "url_big_south = 'https://www.sports-reference.com/cbb/conferences/big-south/{}-stats.html'\n",
    "url_big_sky = 'https://www.sports-reference.com/cbb/conferences/big-sky/{}-stats.html'\n",
    "url_america_east = 'https://www.sports-reference.com/cbb/conferences/america-east/{}-stats.html'\n",
    "url_horizon = 'https://www.sports-reference.com/cbb/conferences/horizon/{}-stats.html'\n",
    "url_patriot = 'https://www.sports-reference.com/cbb/conferences/patriot/{}-stats.html'\n",
    "url_southland = 'https://www.sports-reference.com/cbb/conferences/southland/{}-stats.html'\n",
    "url_northeast = 'https://www.sports-reference.com/cbb/conferences/northeast/{}-stats.html'\n",
    "url_meac = 'https://www.sports-reference.com/cbb/conferences/meac/{}-stats.html'\n",
    "url_swac = 'https://www.sports-reference.com/cbb/conferences/swac/{}-stats.html'\n",
    "url_draft =     'https://www.nbadraft.net/{}-nba-draft-combine-measurements/'\n",
    "url_draft_summary = 'https://basketball.realgm.com/nba/draft/past_drafts/{}'\n",
    "\n",
    "list_of_urls = [\n",
    "url_big12, \n",
    "url_sec, \n",
    "url_big10,\n",
    "url_bigeast,\n",
    "url_pac12,\n",
    "url_acc,\n",
    "url_aac,\n",
    "url_mwc,\n",
    "url_wcc,\n",
    "url_a10,\n",
    "url_mvc,\n",
    "url_cusa,\n",
    "url_col,\n",
    "url_south,\n",
    "url_wac,\n",
    "url_maac,\n",
    "url_bw,\n",
    "url_sb,\n",
    "url_ivy,\n",
    "url_mac,\n",
    "url_as,\n",
    "url_ovc ,\n",
    "url_summit,\n",
    "url_big_south,\n",
    "url_big_sky,\n",
    "url_america_east,\n",
    "url_horizon,\n",
    "url_patriot,\n",
    "url_southland,\n",
    "url_northeast,\n",
    "url_meac,\n",
    "url_swac\n",
    "]\n",
    "#Table ID\n",
    "NCAA_id = 'conference-stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19644134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates File name\n",
    "def generate_name(url, year):\n",
    "    end_index = url[49:].find('/')\n",
    "    name = url[49:49+end_index]+'_'+str(year)\n",
    "    return(name)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f36f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates File Directory\n",
    "def generate_directory(directory, file_name):\n",
    "    generated_directory = directory + '/{}.html'.format(file_name)\n",
    "    return(generated_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a168aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to directory\n",
    "def get_html_request(directory, url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open(generate_directory(directory, generate_name(url, year)), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ee924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /NCAA\n",
    "def get_html_request_NCAA(url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open('NCAA/{}.html'.format(generate_name(url, year)), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910f370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /Draft\n",
    "def get_html_request_draft(url):\n",
    "    for year in years:\n",
    "        url_temp = url.format(year)\n",
    "        data = requests.get(url_temp)\n",
    "        with open('Draft/{}.html'.format(year), 'w+',encoding=\"utf-8\") as f:\n",
    "                f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe4780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads HTML File from given URL to /NCAA, uses Selenium to execute javascript if required\n",
    "def get_html_api(url):\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    for year in years:        \n",
    "        temp_url = url.format(year)\n",
    "        driver.get(temp_url)\n",
    "        driver.execute_script(\"window.scrollTo(1,10000)\")\n",
    "        time.sleep(4)\n",
    "        with open(\"NCAA/{}.html\".format(generate_name(url, year)), \"w+\",encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e65da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searches webpage for all tables\n",
    "def search_url_for_tables(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    return(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8877f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses requests to get html and searches for all tables, returning them as a df with first row as header\n",
    "def get_df_from_url(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    df = pd.read_html(str(tables))[0]\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data unless the header row\n",
    "    df.columns = new_header\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872efe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses requests to get html and searches for all tables, returning them as a df with no header\n",
    "def get_df_from_url_noheader(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tables = soup.find_all('table')\n",
    "    df = pd.read_html(str(tables))[0]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a31b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens html file and extracts table to df from table id\n",
    "def html_to_df_from_tableid(file_name, table_id):\n",
    "    with open('NCAA/{}.html'.format(file_name), encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        soup.find('tr', class_= 'over_header').decompose() #Removes 'over_header' element of table\n",
    "        table = soup.find(id=table_id)\n",
    "        df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "#Uses URL to get df based on table id\n",
    "def html_to_df_from_tableid_no_download(url, table_id):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    table = soup.find(id=table_id)\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "#Uses URL to get df based on table class\n",
    "def html_to_df_from_table_class_no_download(url):\n",
    "    r = get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    table = soup.find('table', {'class' : [\"tablesaw\", \"tablesaw-swipe\", \"tablesaw-sortable\"]})\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52bfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes Positons from player names as to only include player name in 'Player' Collumn\n",
    "def clean_player_name(series):\n",
    "    new_series = []\n",
    "    for item in series:\n",
    "        index = 0\n",
    "        for char in reversed(item):\n",
    "            if char.capitalize() == char or char == '-':\n",
    "                index = index - 1\n",
    "            else:\n",
    "                break\n",
    "        new_series.append(item[:index].strip())\n",
    "    return(new_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b100d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts from inches to cm so model can interpret data\n",
    "def inch_to_cm(series):\n",
    "    new_series = []\n",
    "    for measurement in series:\n",
    "        measurement = measurement.strip()\n",
    "        feet = float(measurement[0])\n",
    "        inches = float(measurement[2:-1])\n",
    "        height_inches = feet*12 + inches\n",
    "        height_cm = round(height_inches * 2.54, 2)\n",
    "        new_series.append(height_cm)\n",
    "    return(new_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fac48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes instances in dataset where last character is a non-int value \n",
    "def remove_last_char(series):\n",
    "    new_series = []\n",
    "    for item in series:\n",
    "        if isinstance(item, str):\n",
    "            if item[-1] == '‘' or item[-1] == '′' or item[-1] == '%':\n",
    "                new_series.append(item[:-1])\n",
    "            else:\n",
    "                new_series.append(item)\n",
    "        else:\n",
    "            new_series.append(item)\n",
    "    return(new_series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88937574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import players\n",
    "from nba_api.stats.endpoints import draftcombinestats\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "combine_dfs = []\n",
    "for year in years:\n",
    "    combine = draftcombinestats.DraftCombineStats(season_all_time = year)\n",
    "    combine_df = combine.get_data_frames()\n",
    "    \n",
    "    combine_dfs.append(combine_df[0])\n",
    "    sleep(0.6)\n",
    "combine_data_df = pd.concat(combine_dfs)\n",
    "\n",
    "combine_data_df.to_csv('combine_total.csv')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b49ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time = 15:30 for .unique()\n",
    "\n",
    "from nba_api.stats.static import players\n",
    "from nba_api.stats.endpoints import draftcombinestats\n",
    "from nba_api.stats.endpoints import commonplayerinfo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_draft_info():\n",
    "    \n",
    "    draft_dfs = []\n",
    "    \n",
    "    player_dict = players.get_players()\n",
    "    for player in player_dict:\n",
    "        if player['full_name'] in combine_data_df['PLAYER_NAME'].unique(): #try list() and .values()\n",
    "            player_info = commonplayerinfo.CommonPlayerInfo(player_id=player['id'])\n",
    "            df = player_info.get_data_frames()\n",
    "            draft_dfs.append(df[0])\n",
    "            sleep(0.6)\n",
    "            \n",
    "    draft_data_df = pd.concat(draft_dfs)\n",
    "    important_columns = ['PERSON_ID', 'DISPLAY_FIRST_LAST', 'SCHOOL', 'BIRTHDATE', 'SEASON_EXP', 'DRAFT_YEAR', 'DRAFT_ROUND', 'DRAFT_NUMBER']\n",
    "    \n",
    "    draft_df = draft_data_df[important_columns]\n",
    "    \n",
    "    '''\n",
    "    for player in combine_data_df['PLAYER_ID']:\n",
    "        print(player)\n",
    "        draft = commonplayerinfo.CommonPlayerInfo(player_id = player)\n",
    "        draft_df = draft.get_data_frames()\n",
    "        draft_dfs.append(draft_df[0])\n",
    "        sleep(0.5)\n",
    "    draft_data_df = pd.concat(draft_dfs)\n",
    "    \n",
    "\n",
    "     \n",
    "    player_dict = players.get_players()\n",
    "    for player in player_dict:\n",
    "        if player['full_name'] == name:\n",
    "            player_info = commonplayerinfo.CommonPlayerInfo(player_id=player['id'])\n",
    "            df = player_info.get_data_frames()\n",
    "            df[1]['SCHOOL'] = df[0]['SCHOOL']\n",
    "    '''\n",
    "    \n",
    "    return(draft_df)\n",
    "    \n",
    "draft_df = get_draft_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b515921",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_rename = {'DISPLAY_FIRST_LAST': 'Player'}\n",
    "draft_df.rename(columns = columns_to_rename)\n",
    "draft_df.to_csv('draft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c6a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = list(combine_data_df.columns)\n",
    "columns_to_drop =   ['HEIGHT_W_SHOES',\n",
    "                     'HEIGHT_W_SHOES_FT_IN',\n",
    "                     'HEIGHT_WO_SHOES_FT_IN',\n",
    "                     'WINGSPAN_FT_IN',\n",
    "                     'BODY_FAT_PCT',\n",
    "                     'HAND_LENGTH',\n",
    "                     'HAND_WIDTH',\n",
    "                     'MODIFIED_LANE_AGILITY_TIME',\n",
    "                     'SPOT_FIFTEEN_CORNER_LEFT',\n",
    "                     'SPOT_FIFTEEN_BREAK_LEFT',\n",
    "                     'SPOT_FIFTEEN_TOP_KEY',\n",
    "                     'SPOT_FIFTEEN_BREAK_RIGHT',\n",
    "                     'SPOT_FIFTEEN_CORNER_RIGHT',\n",
    "                     'SPOT_COLLEGE_CORNER_LEFT',\n",
    "                     'SPOT_COLLEGE_BREAK_LEFT',\n",
    "                     'SPOT_COLLEGE_TOP_KEY',\n",
    "                     'SPOT_COLLEGE_BREAK_RIGHT',\n",
    "                     'SPOT_COLLEGE_CORNER_RIGHT',\n",
    "                     'SPOT_NBA_CORNER_LEFT',\n",
    "                     'SPOT_NBA_BREAK_LEFT',\n",
    "                     'SPOT_NBA_TOP_KEY',\n",
    "                     'SPOT_NBA_BREAK_RIGHT',\n",
    "                     'SPOT_NBA_CORNER_RIGHT',\n",
    "                     'OFF_DRIB_FIFTEEN_BREAK_LEFT',\n",
    "                     'OFF_DRIB_FIFTEEN_TOP_KEY',\n",
    "                     'OFF_DRIB_FIFTEEN_BREAK_RIGHT',\n",
    "                     'OFF_DRIB_COLLEGE_BREAK_LEFT',\n",
    "                     'OFF_DRIB_COLLEGE_TOP_KEY',\n",
    "                     'OFF_DRIB_COLLEGE_BREAK_RIGHT',\n",
    "                     'ON_MOVE_FIFTEEN',\n",
    "                     'ON_MOVE_COLLEGE',\n",
    "                     ]                                       #2016 = none\n",
    "\n",
    "combine_df = combine_data_df.drop(columns = columns_to_drop)\n",
    "combine_df = combine_df.dropna()\n",
    "\n",
    "\n",
    "columns_to_rename = {'PLAYER_NAME': 'Player'}\n",
    "combine_df = combine_df.rename(columns = columns_to_rename)\n",
    "combine_df.to_csv('combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81be247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor url in list_of_urls:\\n    get_html_api(url)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapes around 200 webpages from basketball reference, Saves files in /NCAA\n",
    "#Can run it if you would like but Selenium may crash every once in a while\n",
    "#If this occurs I would suggest indexing list_of_urls to avoid scraping pages already scraped before the crash and re-running cell\n",
    "'''\n",
    "for url in list_of_urls:\n",
    "    get_html_api(url)\n",
    "'''\n",
    "#All files nessecary already in /NCAA directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406a57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goes through each HTML file in NCAA and extracts table as a df and adds it to the dfs_college list \n",
    "#If no table/player data in HTML, file is deleted\n",
    "#Cell will take around 5 minutes to run\n",
    "dfs_college = []\n",
    "for url in list_of_urls:\n",
    "    for year in years:\n",
    "        file_name = generate_name(url, year)\n",
    "        path = Path('./NCAA/{}.html'.format(file_name))\n",
    "        if os.path.isfile(path):                                       #Checks if file exists\n",
    "            with open('NCAA/{}.html'.format(file_name), encoding=\"utf-8\") as f:\n",
    "                page = f.read()\n",
    "                soup = BeautifulSoup(page, 'html.parser')\n",
    "                try:                                                   #Creates df from player data table and adds it to a list\n",
    "                    soup.find('tr', class_= 'over_header').decompose() #This will raise AttributeError if there is no player data on webpage\n",
    "                    table = soup.find(id=NCAA_id)                      \n",
    "                    df = pd.read_html(str(table))[0]\n",
    "                    df['Year'] = year\n",
    "                    dfs_college.append(df)\n",
    "                except AttributeError:                                 #If no player data table exists the HTML file is deleted\n",
    "                    f.close()                                          #This occurs because some conferences did not exist until later \n",
    "                    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc0a82f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Merges df containing college player stats and NBA draft info to a single df which is written to total.csv for analysis\\ntotal = pd.merge(college_total_clean, combine_df, on=['Player', 'Year'])\\ntotal['3P%'] = total['3P%'].fillna(0)\\ntotal = total.dropna()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adds all college players to a single df and gets relevant collumns\n",
    "college_total = pd.concat(dfs_college)\n",
    "relevant_columns = ['Player', 'Pos', 'G','MP','FG%','2P%','3P%','FT%','PTS.1','TRB.1','AST.1','STL.1','BLK.1','PER','WS','BPM', 'Year']\n",
    "columns_to_rename = {'PTS.1': 'PTS',\n",
    "                    'AST.1': 'AST',\n",
    "                    'STL.1': 'STL',\n",
    "                    'BLK.1': 'BLK',\n",
    "                    'TRB.1': 'TRB'}\n",
    "\n",
    "college_total_clean = college_total.loc[:,relevant_columns]\n",
    "college_total_clean.rename(columns = columns_to_rename , inplace = True)\n",
    "\n",
    "college_total_clean.to_csv('NCAA Stats')\n",
    "\n",
    "'''\n",
    "#Merges df containing college player stats and NBA draft info to a single df which is written to total.csv for analysis\n",
    "total = pd.merge(college_total_clean, combine_df, on=['Player', 'Year'])\n",
    "total['3P%'] = total['3P%'].fillna(0)\n",
    "total = total.dropna()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beda5752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG%</th>\n",
       "      <th>2P%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>PTS</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ochai Agbaji</td>\n",
       "      <td>G</td>\n",
       "      <td>31</td>\n",
       "      <td>1032</td>\n",
       "      <td>.428</td>\n",
       "      <td>.519</td>\n",
       "      <td>.338</td>\n",
       "      <td>.673</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avery Anderson</td>\n",
       "      <td>G</td>\n",
       "      <td>30</td>\n",
       "      <td>459</td>\n",
       "      <td>.364</td>\n",
       "      <td>.434</td>\n",
       "      <td>.077</td>\n",
       "      <td>.800</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yor Anei</td>\n",
       "      <td>F</td>\n",
       "      <td>32</td>\n",
       "      <td>650</td>\n",
       "      <td>.484</td>\n",
       "      <td>.486</td>\n",
       "      <td>.333</td>\n",
       "      <td>.704</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>20.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dylan Arnette</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Owen Aschieris</td>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Player</td>\n",
       "      <td>Pos</td>\n",
       "      <td>G</td>\n",
       "      <td>MP</td>\n",
       "      <td>FG%</td>\n",
       "      <td>2P%</td>\n",
       "      <td>3P%</td>\n",
       "      <td>FT%</td>\n",
       "      <td>PTS</td>\n",
       "      <td>TRB</td>\n",
       "      <td>AST</td>\n",
       "      <td>STL</td>\n",
       "      <td>BLK</td>\n",
       "      <td>PER</td>\n",
       "      <td>WS</td>\n",
       "      <td>BPM</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Darrian Wilson</td>\n",
       "      <td>G</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>.182</td>\n",
       "      <td>.333</td>\n",
       "      <td>.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Jamil Wilson</td>\n",
       "      <td>G</td>\n",
       "      <td>26</td>\n",
       "      <td>290</td>\n",
       "      <td>.311</td>\n",
       "      <td>.344</td>\n",
       "      <td>.154</td>\n",
       "      <td>.583</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-10.4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Kobe Wilson</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>618</td>\n",
       "      <td>.396</td>\n",
       "      <td>.410</td>\n",
       "      <td>.167</td>\n",
       "      <td>.591</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Osa Wilson</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>.364</td>\n",
       "      <td>.350</td>\n",
       "      <td>.500</td>\n",
       "      <td>.500</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5093 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Pos   G    MP   FG%   2P%   3P%   FT%   PTS  TRB  AST  \\\n",
       "0      Ochai Agbaji    G  31  1032  .428  .519  .338  .673  10.0  4.2  2.0   \n",
       "1    Avery Anderson    G  30   459  .364  .434  .077  .800   4.2  2.1  1.4   \n",
       "2          Yor Anei    F  32   650  .484  .486  .333  .704   8.1  4.7  0.5   \n",
       "3     Dylan Arnette    G   4     3   NaN   NaN   NaN   NaN   0.0  0.0  0.0   \n",
       "4    Owen Aschieris    G   9    18  .500   NaN  .500   NaN   0.3  0.2  0.1   \n",
       "..              ...  ...  ..   ...   ...   ...   ...   ...   ...  ...  ...   \n",
       "175          Player  Pos   G    MP   FG%   2P%   3P%   FT%   PTS  TRB  AST   \n",
       "176  Darrian Wilson    G  19   128  .182  .333  .158   NaN   0.6  0.6  0.4   \n",
       "177    Jamil Wilson    G  26   290  .311  .344  .154  .583   2.4  0.9  1.0   \n",
       "178     Kobe Wilson    F  30   618  .396  .410  .167  .591   3.3  6.0  0.9   \n",
       "179      Osa Wilson    F   8    50  .364  .350  .500  .500   2.5  1.9  0.3   \n",
       "\n",
       "     STL  BLK   PER    WS    BPM  Year  \n",
       "0    1.2  0.3  13.1   3.4    6.1  2020  \n",
       "1    1.0  0.3   7.9   0.2    0.1  2020  \n",
       "2    0.6  1.9  20.6   2.6    4.8  2020  \n",
       "3    0.0  0.0   0.0   0.0   -4.5  2020  \n",
       "4    0.0  0.0   9.2   0.1    0.2  2020  \n",
       "..   ...  ...   ...   ...    ...   ...  \n",
       "175  STL  BLK   PER    WS    BPM  2020  \n",
       "176  0.1  0.0  -2.0   0.0  -14.0  2020  \n",
       "177  0.2  0.0   3.0  -0.4  -10.4  2020  \n",
       "178  0.7  1.2  14.2   1.6   -2.4  2020  \n",
       "179  0.5  0.0  15.9   0.1   -9.0  2020  \n",
       "\n",
       "[5093 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_total_clean.loc[college_total_clean['Year'] == 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ada22f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>G</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG%</th>\n",
       "      <th>2P%</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>PTS</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PER</th>\n",
       "      <th>WS</th>\n",
       "      <th>BPM</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe Adkins</td>\n",
       "      <td>G</td>\n",
       "      <td>34</td>\n",
       "      <td>1006</td>\n",
       "      <td>.366</td>\n",
       "      <td>.380</td>\n",
       "      <td>.350</td>\n",
       "      <td>.831</td>\n",
       "      <td>11.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glendon Alexander</td>\n",
       "      <td>G</td>\n",
       "      <td>34</td>\n",
       "      <td>815</td>\n",
       "      <td>.465</td>\n",
       "      <td>.505</td>\n",
       "      <td>.442</td>\n",
       "      <td>.773</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austin Allen</td>\n",
       "      <td>G</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>.143</td>\n",
       "      <td>.000</td>\n",
       "      <td>.167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victor Avila</td>\n",
       "      <td>C</td>\n",
       "      <td>34</td>\n",
       "      <td>529</td>\n",
       "      <td>.490</td>\n",
       "      <td>.486</td>\n",
       "      <td>1.000</td>\n",
       "      <td>.686</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luke Axtell</td>\n",
       "      <td>G</td>\n",
       "      <td>20</td>\n",
       "      <td>323</td>\n",
       "      <td>.348</td>\n",
       "      <td>.303</td>\n",
       "      <td>.392</td>\n",
       "      <td>.739</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Darrian Wilson</td>\n",
       "      <td>G</td>\n",
       "      <td>18</td>\n",
       "      <td>239</td>\n",
       "      <td>.357</td>\n",
       "      <td>.375</td>\n",
       "      <td>.350</td>\n",
       "      <td>.714</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Kobe Wilson</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>184</td>\n",
       "      <td>.455</td>\n",
       "      <td>.476</td>\n",
       "      <td>.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Cameron Woodall</td>\n",
       "      <td>G</td>\n",
       "      <td>11</td>\n",
       "      <td>188</td>\n",
       "      <td>.438</td>\n",
       "      <td>.466</td>\n",
       "      <td>.333</td>\n",
       "      <td>.622</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Desean Woods</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>.167</td>\n",
       "      <td>.250</td>\n",
       "      <td>.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Ryan Woods</td>\n",
       "      <td>G</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>.571</td>\n",
       "      <td>.600</td>\n",
       "      <td>.500</td>\n",
       "      <td>.000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105020 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Pos   G    MP   FG%   2P%    3P%    FT%   PTS  TRB  \\\n",
       "0           Joe Adkins   G  34  1006  .366  .380   .350   .831  11.1  3.5   \n",
       "1    Glendon Alexander   G  34   815  .465  .505   .442   .773  11.7  2.4   \n",
       "2         Austin Allen   G  12    54  .143  .000   .167  1.000   0.4  0.1   \n",
       "3         Victor Avila   C  34   529  .490  .486  1.000   .686   5.2  4.4   \n",
       "4          Luke Axtell   G  20   323  .348  .303   .392   .739   8.7  2.8   \n",
       "..                 ...  ..  ..   ...   ...   ...    ...    ...   ...  ...   \n",
       "154     Darrian Wilson   G  18   239  .357  .375   .350   .714   1.8  1.1   \n",
       "155        Kobe Wilson   F  14   184  .455  .476   .000  1.000   1.6  3.1   \n",
       "156    Cameron Woodall   G  11   188  .438  .466   .333   .622   8.4  2.5   \n",
       "157       Desean Woods   G   4    51  .167  .250   .125    NaN   1.3  0.5   \n",
       "158         Ryan Woods   G   8    34  .571  .600   .500   .000   1.1  0.0   \n",
       "\n",
       "     AST  STL  BLK   PER    WS    BPM  Year  \n",
       "0    4.1  1.3  0.1   NaN   2.8    NaN  2000  \n",
       "1    0.9  0.5  0.0   NaN   3.9    NaN  2000  \n",
       "2    0.4  0.3  0.0   NaN   0.0    NaN  2000  \n",
       "3    0.6  0.2  0.4   NaN   2.5    NaN  2000  \n",
       "4    1.2  0.9  0.4   NaN   1.0    NaN  2000  \n",
       "..   ...  ...  ...   ...   ...    ...   ...  \n",
       "154  0.3  0.6  0.2   5.2   0.6   -4.7  2021  \n",
       "155  0.2  0.4  0.2   9.9   0.3   -4.3  2021  \n",
       "156  0.8  0.5  0.5  15.9   0.5   -0.6  2021  \n",
       "157  2.0  0.3  0.0  -7.1  -0.1  -16.3  2021  \n",
       "158  0.3  0.5  0.0  11.1   0.0   -1.0  2021  \n",
       "\n",
       "[105020 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_total_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a8a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
